{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8ef54e-2662-4849-aeaf-ee4e791b43e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0634ca-f9be-4d3a-b1a8-fc8a2c5814f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18068de3-598b-40d1-a01f-b77e21ab7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratio,dataset):\n",
    "    train_size = int(ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e355d46-9e98-4c24-884a-696f74888ce7",
   "metadata": {},
   "source": [
    "# Swin Transformer V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64a46289-e8f6-44a6-984d-4d0f41e2fb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, SwinForImageClassification\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b9c0c8b-7860-4035-adda-33f56dcf0b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdd5b891e884f088229d9cfa7816509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/12446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"D:/data/kidney_dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fc3d5ee4-7a15-4829-bc41-863b93d0df78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 12446\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e11d76f8-aa0c-4d47-a7dc-2f363b01254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 12446\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3228fd0a-5926-48cb-8567-9e53018759fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8b1ecd5c-22f7-482b-aede-f531ea5719dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a4ca9e2b-883e-4a3a-bf51-ca04d0e3af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(trial):\n",
    "    return SwinForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ebecef82-ff2d-4a29-a1fe-e2b2cf0b17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "607bfdaa-07da-4df7-a8a1-1fbd84cc5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def search_space_swinv1(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4),  # Learning rate search space\n",
    "        \"num_train_epochs\": trial.suggest_categorical(\"num_train_epochs\", [5, 10, 15]),  # Number of training epochs\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),  # Batch size per device during training\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3),  # Weight decay\n",
    "        \"attention_dropout\": trial.suggest_uniform(\"attention_dropout\", 0.1, 0.3),  # Attention dropout rate\n",
    "        \"dropout\": trial.suggest_uniform(\"dropout\", 0.1, 0.3),  # Dropout rate\n",
    "        # You can add more hyperparameters to the search space as needed\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "08106bd0-bc66-4150-a919-b6d2515ccd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits,labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metrics.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f42bd00c-b0d9-45e9-bb54-c0a17f053af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_dir='./logs',  # Use the trial log directory\n",
    "        logging_steps=100,\n",
    "        save_steps=1000,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "828bdde5-08d1-4745-a85c-73a3d4bdceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 11201\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 1245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "adf3b506-6e3e-44bb-a2a0-fde155307a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].set_transform(image_processor)\n",
    "dataset['test'].set_transform(image_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0105b690-a230-4359-a005-30f9fbf299d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 11201\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9dcbd277-f7f6-4b1c-9718-8f00e9da17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f06b15-9a62-4bd0-b340-88facfad98b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa88244f-04fc-49cb-9013-1ada3a0e5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=None,\n",
    "    train_dataset =train_loader,\n",
    "    eval_dataset = test_loader,\n",
    "    compute_metrics=compute_metrics,\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    # data_collator=data_collator\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "422925a2-7128-4dfa-9721-2629baab50b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-07 09:03:26,350] A new study created in memory with name: no-name-5517406d-1098-485c-864e-30f1623ba7c9\n",
      "C:\\Users\\Sid Sitaula\\AppData\\Local\\Temp\\ipykernel_1264\\1920647734.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-4),  # Learning rate search space\n",
      "C:\\Users\\Sid Sitaula\\AppData\\Local\\Temp\\ipykernel_1264\\1920647734.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-3),  # Weight decay\n",
      "C:\\Users\\Sid Sitaula\\AppData\\Local\\Temp\\ipykernel_1264\\1920647734.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"attention_dropout\": trial.suggest_uniform(\"attention_dropout\", 0.1, 0.3),  # Attention dropout rate\n",
      "C:\\Users\\Sid Sitaula\\AppData\\Local\\Temp\\ipykernel_1264\\1920647734.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"dropout\": trial.suggest_uniform(\"dropout\", 0.1, 0.3),  # Dropout rate\n",
      "Trying to set attention_dropout in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "Trying to set dropout in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\n",
      "[W 2024-04-07 09:03:28,214] Trial 0 failed with parameters: {'learning_rate': 2.1462410556808757e-05, 'num_train_epochs': 15, 'per_device_train_batch_size': 8, 'weight_decay': 0.00016125720620660888, 'attention_dropout': 0.1427954540964021, 'dropout': 0.2894530421307555} because of the following error: TypeError(\"'DataLoader' object is not subscriptable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\integrations.py\", line 208, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\trainer.py\", line 1645, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\trainer.py\", line 1907, in _inner_training_loop\n",
      "    for step, inputs in enumerate(epoch_iterator):\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "TypeError: 'DataLoader' object is not subscriptable\n",
      "[W 2024-04-07 09:03:28,231] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_trail \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mhyperparameter_search(\n\u001b[0;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     hp_space \u001b[38;5;241m=\u001b[39m search_space_swinv1,\n\u001b[0;32m      4\u001b[0m      n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\trainer.py:2643\u001b[0m, in \u001b[0;36mTrainer.hyperparameter_search\u001b[1;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[0;32m   2635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_objective \u001b[38;5;241m=\u001b[39m default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[0;32m   2637\u001b[0m backend_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2638\u001b[0m     HPSearchBackend\u001b[38;5;241m.\u001b[39mOPTUNA: run_hp_search_optuna,\n\u001b[0;32m   2639\u001b[0m     HPSearchBackend\u001b[38;5;241m.\u001b[39mRAY: run_hp_search_ray,\n\u001b[0;32m   2640\u001b[0m     HPSearchBackend\u001b[38;5;241m.\u001b[39mSIGOPT: run_hp_search_sigopt,\n\u001b[0;32m   2641\u001b[0m     HPSearchBackend\u001b[38;5;241m.\u001b[39mWANDB: run_hp_search_wandb,\n\u001b[0;32m   2642\u001b[0m }\n\u001b[1;32m-> 2643\u001b[0m best_run \u001b[38;5;241m=\u001b[39m backend_dict[backend](\u001b[38;5;28mself\u001b[39m, n_trials, direction, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhp_search_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\integrations.py:218\u001b[0m, in \u001b[0;36mrun_hp_search_optuna\u001b[1;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    217\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 218\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(_objective, n_trials\u001b[38;5;241m=\u001b[39mn_trials, timeout\u001b[38;5;241m=\u001b[39mtimeout, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)\n\u001b[0;32m    219\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BestRun(\u001b[38;5;28mstr\u001b[39m(best_trial\u001b[38;5;241m.\u001b[39mnumber), best_trial\u001b[38;5;241m.\u001b[39mvalue, best_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\integrations.py:208\u001b[0m, in \u001b[0;36mrun_hp_search_optuna.<locals>._objective\u001b[1;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[0;32m    206\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain(resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# If there hasn't been any evaluation during the training loop.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1642\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1644\u001b[0m )\n\u001b[1;32m-> 1645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1646\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1647\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1648\u001b[0m     trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1650\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\transformers\\trainer.py:1907\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1904\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1906\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1907\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1908\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "best_trail = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    hp_space = search_space_swinv1,\n",
    "     n_trials=20,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f46b9b47-8efe-4d87-b545-1aba14c36a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\data_sid\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17d0b6ae-439f-4fa7-b815-3bac3651e8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x28726b17f10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7522b1-8140-4f7d-8d5b-e0f832f144f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2992f6a-5abc-41cb-936e-9019cce2abe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
